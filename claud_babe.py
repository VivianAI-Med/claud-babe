# -*- coding: utf-8 -*-
"""claud babe.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14ACweKXMEE9rvvzxuySElrYDNfS_4ttQ
"""

pip install ucimlrepo

from ucimlrepo import fetch_ucirepo

# fetch dataset
regensburg_pediatric_appendicitis = fetch_ucirepo(id=938)

# data (as pandas dataframes): Yes, when you use the ucimlrepo library to fetch a dataset,
#it is designed to consistently provide the data in a structured format.
#The features are typically accessible through the .data.features attribute and the targets through the .data.targets attribute of the fetched object.
#This makes it convenient to access the different parts of the dataset for machine learning tasks.


X = regensburg_pediatric_appendicitis.data.features
y = regensburg_pediatric_appendicitis.data.targets

# metadata
print(regensburg_pediatric_appendicitis.metadata)

# variable information
print(regensburg_pediatric_appendicitis.variables)

X.head()

from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
import pandas as pd
import numpy as np

# Identify columns with missing values
missing_values_cols = X.columns[X.isnull().any()].tolist()
print(f"Columns with missing values: {missing_values_cols}")

# Separate numerical and categorical columns
numerical_cols = X.select_dtypes(include=np.number).columns.tolist()
categorical_cols = X.select_dtypes(include='object').columns.tolist()

# Define preprocessing steps for numerical and categorical features
numerical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())
])

categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder(handle_unknown='ignore'))
])

# Create a column transformer to apply different transformations to different columns
preprocessor = ColumnTransformer(
    transformers=[
        ('num', numerical_transformer, numerical_cols),
        ('cat', categorical_transformer, categorical_cols)
    ])

# Apply preprocessing to the features
X_preprocessed = preprocessor.fit_transform(X)

# Convert the preprocessed data back to a DataFrame (optional, but useful for inspection)
# Get feature names after one-hot encoding
onehot_feature_names = preprocessor.named_transformers_['cat']['onehot'].get_feature_names_out(categorical_cols)
all_feature_names = numerical_cols + list(onehot_feature_names)

X_processed_df = pd.DataFrame(X_preprocessed, columns=all_feature_names)

display(X_processed_df.head())
print(f"Shape of preprocessed data: {X_processed_df.shape}")

from sklearn.model_selection import train_test_split

# Define the target variable y
y = y['Diagnosis']

# Split the preprocessed data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_processed_df, y, test_size=0.2, random_state=42)

print("Shape of X_train:", X_train.shape)
print("Shape of X_test:", X_test.shape)
print("Shape of y_train:", y_train.shape)
print("Shape of y_test:", y_test.shape)

from sklearn.linear_model import LogisticRegression
from sklearn.impute import SimpleImputer

# Instantiate an imputer for categorical data: used to handle missing values.
imputer_y = SimpleImputer(strategy='most_frequent')

# Reshape y_train for imputation
y_train_reshaped = y_train.values.reshape(-1, 1)

# Impute missing values in y_train
y_train_imputed = imputer_y.fit_transform(y_train_reshaped)

# Convert back to a 1D array
y_train_imputed = y_train_imputed.ravel()

# Reshape y_test for imputation
y_test_reshaped = y_test.values.reshape(-1, 1)

# Impute missing values in y_test
y_test_imputed = imputer_y.transform(y_test_reshaped)

# Convert back to a 1D array
y_test_imputed = y_test_imputed.ravel()


# Instantiate a LogisticRegression model
model = LogisticRegression()

# Train the logistic regression model
model.fit(X_train, y_train_imputed)

from sklearn.impute import SimpleImputer

# Instantiate an imputer for categorical data
imputer_y = SimpleImputer(strategy='most_frequent')

# Reshape y_train for imputation
y_train_reshaped = y_train.values.reshape(-1, 1)

# Impute missing values in y_train
y_train_imputed = imputer_y.fit_transform(y_train_reshaped)

# Convert back to a 1D array
y_train_imputed = y_train_imputed.ravel()

# Reshape y_test for imputation
y_test_reshaped = y_test.values.reshape(-1, 1)

# Impute missing values in y_test
y_test_imputed = imputer_y.transform(y_test_reshaped)

# Convert back to a 1D array
y_test_imputed = y_test_imputed.ravel()


# Instantiate a LogisticRegression model
model = LogisticRegression()

# Train the logistic regression model
model.fit(X_train, y_train_imputed)

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# Make predictions on the testing data
y_pred = model.predict(X_test)

# Calculate evaluation metrics
accuracy = accuracy_score(y_test_imputed, y_pred)
precision = precision_score(y_test_imputed, y_pred, pos_label='appendicitis')
recall = recall_score(y_test_imputed, y_pred, pos_label='appendicitis')
f1 = f1_score(y_test_imputed, y_pred, pos_label='appendicitis')

# Print the evaluation metrics
print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1-score: {f1:.4f}")

def preprocess_input(age, bmi, sex):
    # Adjust this based on how you trained your model
    sex_encoded = 0 if sex.lower() == 'female' else 1
    
    # If your model expects different features or order, modify here
    features = np.array([[age, bmi, sex_encoded]])
    
    # Add any additional preprocessing your model needs
    # (scaling, encoding, etc.)
    
    return features
